---
title: "GLMM per art"
author: "Torgeir"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide 
    toc: true
---

```{r setup}
library(tidyverse)
library(lme4)
library(ggeffects) # Estimated Marginal Means and Marginal Effects from Regression Models
# more at: https://strengejacke.github.io/ggeffects/
library(performance) # diagnostic-plots to check assumptions
library(report) # Result-summaries in text-format
# Data drom Data_exploration2_nesting.R
time.dep <- readRDS("timedep.rds")
```

## Purpose

This notebook is meant to set up the final GLMModels going into my thesis. Upset is identical to the "glmm_in_process"-file, but structure is different as I'm going to make one model for each species. I will write my thoughts about each model as I go along, which will guide me in the writing of method, result and discussion.

# About the model

### Why GLMM?

Response from a [stackexchange question](https://stats.stackexchange.com/questions/226946/r-lmer-vs-glmer)
about the differences of `lmer` and `glmer`-functions:

>lmer is used to fit linear mixed-effect models, so it assumes that the residual error has a Gaussian distribution. If your dependent variable A is a binary outcome (e.g. a yes/no response), then the error distribution is binomial and not Gaussian. In this case you have to use glmer, which allow to fit a generalized linear mixed-effects model: these models include a link function that allows to predict response variables with non-Gaussian distributions. One example of link function that could work in your case is the logistic function, which takes an input with any value from negative to positive infinity and return an output that always takes values between zero and one, which is interpretable as the probability of the binary outcome (e.g. the probability of the subject responding 'yes').




### Formula
The model formula I will use is $n \sim \ time.deploy\ * flash $ for each species, and my $\alpha = 0.05$.

```{r timedep2}
sp <- c("raadyr", "rev", "hjort", "grevling", "elg", "gaupe")
ctrl <- c("Control_1", "Control_2", "Control_3","Control_4")
time.dep2 <- time.dep %>% 
  rename(species = validated_species) %>%  #shortening name
  filter(species %in% sp) %>% #filtering out species
  # including Control as part of the flash-column, since it differs from flash=0
  mutate(flash = factor(
        ifelse(period %in% ctrl, "Control", flash)),
         week = lubridate::isoweek(date))
# time.dep2 <- time.dep2c %>% 
#   filter(!period %in% ctrl) %>%  # but removing it for now, because it is set up in a longer timeframe
#   mutate(flash = factor(flash, levels = c(0,1)) )
# class(time.dep2$flash)
```

Not all periods have identical length. Hence, I need to set a maximum length for my period durations. As proposed by Neri, I will calculate the median for white LED-periods and IR-periods, and use the smallest median to shorten all periods overextending that value.

First I'll filter out any periods shorter than 4 days ( _as of 18.02.2021, only 1 period_ ). 
Then I'll cut the duration of all periods overextending the smallest median.


```{r period-median, message=FALSE}
# filter out shortest periods, and find median period length
cut <- .5 # setting the minimum length of a period
# find lengths
time.period <- time.dep2 %>% group_by(loc, period, flash) %>% 
  summarise(period_length = max(time.deploy))
# checking which periods will be removed
time.period %>% filter(period_length <= cut) %>%
  arrange(period_length) #%>% kableExtra::kable("html")
# then merge lengths and filter based on that
time.dep3 <- time.dep2 %>% left_join(time.period) %>%
  filter(period_length >= cut)
# find median length after filtering short lengths out
time.period %>% filter(period_length >= cut) %>% filter(flash == 1) %>%  
  summary() # median period length 85 days, mean: 84
time.period %>% filter(period_length >= cut) %>% filter(flash == 0) %>%  
  summary() # median period length 79 days, mean: 89
# extract lengths of each unique period
h <- time.dep3 %>% group_by(loc, period, period_length, flash)%>% nest() %>% 
  select(!data) 
#extracting median and multiplying by 10, to use in the correctly scaled plot
hh <-       h$period_length[h$flash == 1] %>%  median()       # median white LED
hh <- c(hh, h$period_length[h$flash == 0] %>%  median()) * 10 # + median IR
# smallest median 
h <- min(hh)
```

79 days is the median period length of IR-periods, and it is shorter than the median of white LED flash. The summary also tells us that

__Update:__ With the updated dataset, the IR median has shifted to 84 days, white LED to 85. 84 is the new trimming value.

Periods below 5 days has now been removed, which as of 18.02.2021 (before updated data from Neri) were 1 period.
With new data and Control group, there are 3 periods filtered out, two of which were Control-periods: 

|loc|	period|flash |period_length| 
|---|-------|------|:-----------:|
|829|	1_1   |	1	   | 0.0 = 0 days|
|258|	Ctrl1 |	Ctrl | 0.4 = 4 days|
|460|	Ctrl1 |	Ctrl | 0.5 = 5 days|



```{r period-length, message=FALSE}
# plot periods with median as intercept
p_td <- time.dep3 %>% filter(!period %in% ctrl) %>% 
  ggplot(aes(loc, 10*time.deploy, colour = period, ))  +
  geom_line(aes(linetype = flash),position = position_dodge(width = 1), lineend = "square") +
  coord_flip() + 
  labs(title = "Period lengths per camera",
       x = "Location", y = "Time since deployment",
       caption = "Dotted lines reprecent median period length for IR and white LED.\n Data superceding that is trimmed away for the GLMM-modelling.") +
  ggpubr::theme_classic2() #+ theme(legend.position = "right") find way to set legend inside
p_td + geom_hline(aes(yintercept = h), linetype = "dashed",  alpha =.5) +
  geom_hline(aes(yintercept = max(hh)), linetype = "dashed",  alpha =.5) +
  #annotate(geom = "text",x=4, y=h+8.6, label = "- median", size = 3, alpha =.7) +
  scale_y_continuous(breaks = sort(c(0, 50, h, 100, 150))) +
  scale_color_brewer(palette = "Spectral")
# failed attempts that could inspire a better plot later
# p_td + geom_hline(aes(yintercept = h))+ # using median days as intercept 
#        scale_y_continuous(breaks = sort(c(ggplot_build(p_td)$layout$panel_ranges[[1]]$y.major_source, h)))
# geom_text(aes(25, h, label = "median", vjust = -1), nudge_y = 10, show.legend = F)
```

There was an overweight of IR-periods extending past the median line.


```{r period-length-wControl, message=FALSE, warning=FALSE}
# remake plot with Control-group data, faceted
p_td2 <- time.dep3 %>% 
  ggplot(aes(loc, 10*time.deploy, colour = period))  +
  geom_line(aes(linetype = flash),position = position_dodge(width = 1), lineend = "square") +
  coord_flip() +  
  geom_hline(aes(yintercept = h), linetype = "dashed",  alpha =.5) +
  scale_y_continuous(breaks = sort(c(0, 50, h, 100, 150))) + facet_grid(rows = "flash") +
  labs(title = "Period lengths per camera", x = "Location", y = "Time since deployment",
       caption = "Dotted lines reprecent median period length for IR and white LED.\n Data superceding that is trimmed away for the GLMM-modelling.")
  

p_td2 + ggpubr::theme_classic2() +
  theme(legend.position = "none", axis.text.y = element_blank(), axis.ticks.y = element_blank()) +
        scale_colour_brewer(palette="Spectral")
```



_Lastly, performing the filter:_
```{r time.dep4-filtr}
# filtering out periods longer than (shortest) median length.
time.dep4 <- time.dep3 %>% filter(time.deploy < h/10)
```


# Modelling

## Roe deer

### Diagnostics

```{r raadyr}
time.dep4$loc %>% unique() %>% is.na() %>% any()
summary(time.dep4)

# filter species
sp = "raadyr"
time_sp <- filter(time.dep4, species %in% sp, !period %in% ctrl) #.dep4 = trimmed data
# Model
m_sp  <- lme4::glmer(n.obs ~ time.deploy * flash + # fixed effects
            (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions

# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_sp, terms = c("time.deploy", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(subtitle = "add.data = TRUE")
plot(p_sp, residuals = TRUE) + labs(subtitle = "residuals")
performance::check_model(m_sp) # check assumptions
```


The response variable is a summary of number of events per day. Most days had no roe deer.
In the performance-test for model assumptions _it is clear that some assumptions aren't met._

#### Negative
In the non-normality of resiudals-plot, the residuals skew off from the line when moving towards positive quantiles.
There is _not_ a homogeneity of variance. _Maybe this could be fixed by centering the n.obs-column?_

There appeares to be five influential observations in the Cook's distance-plot, maybe more, as the warning from ggrepel refers to 93 unlabeled data points due to overlaps.

#### Positive
Although the model has an interaction term between flash and time since deployment, the multicollinearity between them is low!
My random effects follows a normal distribution.

#### Concluding
I am not sure about how to make up for breaking these assumptions. For now, I will go on completing models for the rest of the species.

```{r raadyr-report}
# Summary, report, model
summary(m_sp)
# report::report(m_sp) # text-summary of my model, to include in a report
plot(p_sp)
```

### Model interpretation
The intercept-value is considered significantly negative, which is to say that there were a low chance of detecting any roe deer at an IR-camera the same day I visited the camera.

> I saw a roe deer about to walk by a CT when I came to inspect it. The roe deer saw me and fled, right before it was detected by the camera. Chances are I've scared animals other times as well, but haven't noticed it.

The effect of _Time since deployment_ is non-significant, and $\beta = 0.008$.
That means there is no difference on the baseline detection rate for an IR camera over time (after controlling for seasonal changes). 

For white LED flash  $\beta = 0.170$, meaning that the intercept is slightly higher than for IR, but the difference is non-significant ($p = 0.18$).
However, the detection rate is slightly decreasing the longer the white LED stays, which differs from the IR, _
but the effect is non-significant_ ($p = 0.23$).

#### Hypothesising
If there truly is an effect of the white LED for long periods on the detection rate of roe deer, this effect could in turn account for the different intercept values of IR and flash, as the IR periods often start after a flash period.

Remembering my study design, 20 cameras start with white LED, 20 with IR. _Intercept should be equal_ (1st period).
2nd period; white LED moved, new LED CTs (same intercept), new IR CTs (hypothetical lower intercept due to flash effect).
3rd period; white LED moved, new LED CTs (IR intercept), new IR CTs (hypothetical lower intercept).
4th period;  - -  ||  - -  , new LED CTs (- - | | - - ), new IR CTs (   -  -  |  |  -  -  ).

Which sums up to 3 IR periods where detection rates could start lower than that of white LED. And over time the lack of white LED flash in the new IR sites would account for an _increase_ in detection rates.

The effect would of course vary because some locations experienced _gaps_ due to full SD cards or empty batteries.
<!--_Maybe, after my thesis, I could try to pry out these differences-->

-------------------------------------

#### Update!

After uptaded data from Neri; the effect of flash is now deemed significant!
Still the same pattern with higher intercept and a negative slope along the time axis, which further supports my hypothesising above.
The interaction with time since deployment is, however, still non-significant.
_Now I want to look at a model including the Control-group._


```{r raadyr-C}
# filter species
sp = "raadyr"
time_sp <- filter(time.dep4, species %in% sp) #.dep4 = trimmed data

# Model
m_raa  <- glmer(n.obs ~ time.deploy * flash + # fixed effects
              (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions
# --------------------------------------------------------------------
# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_raa, terms = c("time.deploy", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(subtitle  = "Raw data")
plot(p_sp, residuals = TRUE) + labs(subtitle  = "residuals")
performance::check_model(m_raa) # check assumptions
```

There are a couple of extreme counts in the Control-group, even after having filtered away all observations with less than a 15 min interval for each species (ie. setting 15 min margin as definition of an event). These extreme counts are skewed to the left which probably will affect the intercept of control quite a bit, but probably won't deem the intercept-value as significant (as these extreme values are outliers).

The homogeneity of variance is still off. It deems on me more and more that this is due to these extreme count-values that is close to time.deploy = 0. _Will it disappear if I divide by the standard deviation?_

The multicollinearity is moderate for the interaction term of time.deploy and flash when the control group is included. Still, the change is small (in my layman eyes), with a increase in bar height from ~ 4 to ~ 6.



```{r raadyr-C-report}
# Summary, report, model
summary(m_raa)
plot(p_sp)
```

The control intercept is almost on top of the IR-intercept, but it has a more negative trend than the IR-group. After I got updated data and performed the event-filter, the slope of IR changed to a negative trend over time, as well, "removing" any significance from the flash terms. The important thing to note, then, is how small the p-values was, and how easily they turned non-significant.
Looking at the plot, the confidence interval tells us all we need to know, as they almost completely overlap.
The groups are almost identical. The slope of the control group is actually steeper than that of white LED (although only minisculy).
Further, the trend over time with the control-group __should__ be due to chance, _as time.deploy = 0 is seldom the actual day I visited the cameras_. They were visited less often in general, and the breaks leading to time.deploy = 0 are set manually by me, to make period lengths that are similar to those of the IR and white LED group.

### Some parameter-plots from see and effectsize

The CI-plots of effectsize will be included in some form in my thesis. For the equivalence-plot I'm not to sure if I'll use it, but the interpretation is neat with that method. From the bayesian statistics, if a predictor is completely covered by the ROPE-area you can accept the null hypothesis. This is not possible in a frequentist perspective (as my models are), but one could claim _practical equivalence_ if the effect is non-significant AND completely inside the ROPE-interval. Explanations from [Equivalence vignette](https://easystats.github.io/parameters/reference/equivalence_test.lm.html):

>"classic" - The TOST rule (Lakens 2017)
This rule follows the “TOST rule”, i.e. a two one-sided test procedure (Lakens 2017). Following this rule, practical equivalence of an effect (i.e. H0) is rejected, when the coefficient is statistically significant and the narrow confidence intervals (i.e. 1-2*alpha) include or exceed the ROPE boundaries. Practical equivalence is assumed (i.e. H0 accepted) when the narrow confidence intervals are completely inside the ROPE, no matter if the effect is statistically significant or not. Else, the decision whether to accept or reject H0 is undecided.
>"cet" - Conditional Equivalence Testing (Campbell/Gustafson 2018)
The Conditional Equivalence Testing as described by Campbell and Gustafson 2018. According to this rule, practical equivalence is rejected when the coefficient is statistically significant. When the effect is not significant and the narrow confidence intervals are completely inside the ROPE, we accept H0, else it is undecided

```{r parameters}
library(parameters)
library(effectsize)
library(see)
result <- model_parameters(m_raa, standardize = "refit")
plot(result, show_intercept = TRUE)
plot(result, size_text = 3)

# default rules, like in bayestestR::equivalence_test()
result <- equivalence_test(m_raa)
plot(result, size_text = 3)
result

result_sim <- simulate_parameters(m_raa)
plot(result_sim, stack = FALSE,
     normalize_height = TRUE)
```


```{r raadyr-report2}
report::report(m_raa) # text-summary of my model, to include in a report
```




# Skrivestopp

## Red Fox

```{r rev}
# filter species
sp = "rev"
time_sp <- filter(time.dep4, species %in% sp) #.dep4 = trimmed data
# Model
m_rev  <- glmer(n.obs ~ time.deploy * flash + # fixed effects
              (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions

# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_rev, terms = c("time.deploy", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(subtitle = "add.data = TRUE")
plot(p_sp, residuals = TRUE) + labs(subtitle = "residuals")
performance::check_model(m_rev) # check assumptions
```


### Interpret

```{r rev-report}
# Summary, report, model
summary(m_rev)
plot(p_sp)
```


```{r rev-report2}
report::report(m_rev) # text-summary of my model, to include in a report
```




## Badger

```{r grevling}
# filter species
sp = "grevling"
time_sp <- filter(time.dep4, species %in% sp) #.dep4 = trimmed data
# Model
m_grvl  <- glmer(n.obs ~ time.deploy * flash + # fixed effects
              (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions

# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_grvl, terms = c("time.deploy", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(subtitle  = "add.data = TRUE")
plot(p_sp, residuals = TRUE) + labs(subtitle  = "residuals")
performance::check_model(m_grvl) # check assumptions
```


### Interpret

```{r grevling-report}
# Summary, report, model
summary(m_grvl)
plot(p_sp)
```


```{r grevling-report2}
report::report(m_grvl) # text-summary of my model, to include in a report
```




## Moose

```{r elg}
# filter species
sp = "elg"
time_sp <- filter(time.dep4, species %in% sp) #.dep4 = trimmed data
# Model
m_elg  <- glmer(n.obs ~ time.deploy * flash + # fixed effects
              (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions

# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_elg, terms = c("time.deploy", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(subtitle  = "add.data = TRUE")
plot(p_sp, residuals = TRUE) + labs(subtitle  = "residuals")
performance::check_model(m_elg) # check assumptions
```


### Interpret

```{r elg-report}
# Summary, report, model
summary(m_elg)
plot(p_sp)
```


```{r elg-report2}
report::report(m_elg) # text-summary of my model, to include in a report
```




## Red deer

```{r hjort}
# filter species
sp = "hjort"
time_sp <- filter(time.dep4, species %in% sp) #.dep4 = trimmed data
# Model
m_hjort  <- glmer(n.obs ~ time.deploy * flash + # fixed effects
              (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions

# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_hjort, terms = c("time.deploy", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(subtitle  = "add.data = TRUE")
plot(p_sp, residuals = TRUE) + labs(subtitle  = "residuals")
performance::check_model(m_hjort) # check assumptions
```


### Interpret

```{r hjort-report}
# Summary, report, model
summary(m_hjort)
# report::report(m_hjort) # text-summary of my model, to include in a report
plot(p_sp)
```

```{r hjort-report2}
report::report(m_hjort) # text-summary of my model, to include in a report
```



## Lynx

```{r gaupe}
# filter species
sp = "gaupe"
time_sp <- filter(time.dep4, species %in% sp) #.dep4 = trimmed data
# Model
m_gaup  <- glmer(n.obs ~ time.deploy * flash + # fixed effects
              (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions

# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_gaup, terms = c("time.deploy", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(subtitle  = "add.data = TRUE")
plot(p_sp, residuals = TRUE) + labs(subtitle  = "residuals")
performance::check_model(m_gaup) # check assumptions
```


### Interpret

```{r gaupe-report}
# Summary, report, model
summary(m_gaup)
plot(p_sp)
```

```{r gaupe-report2}
report::report(m_gaup) # text-summary of my model, to include in a report
```




----------------------------------------------

```{r model-comparison, eval=FALSE}
# library(rstanarm)
# #result <- #compare_parameters(m_raa, m_rev, m_grvl, m_elg, m_hjort, m_gaup) #can't find function :-/
# plot(result)
# 
# rmarkdown::render("glmm_sp.Rmd", output_format = "github_document")
```






# Hare, deer and squirrelywhere (and pine marten) 

Blueprint for other species in chunk below:

### Diagnostics

```{r xx, eval=FALSE}
# filter species
sp = "xx"
time_sp <- filter(time.dep4, species %in% sp) #.dep4 = trimmed data
# Model
m_sp  <- glmer(n.obs ~ time.deploy * flash + # fixed effects
              (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions

# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_sp, terms = c("time.deploy", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(subtitle  = "add.data = TRUE")
plot(p_sp, residuals = TRUE) + labs(subtitle  = "residuals")
performance::check_model(m_sp) # check assumptions
```


### Interpret

```{r xx-report, eval=FALSE}
# Summary, report, model
summary(m_sp)
report::report(m_sp) # text-summary of my model, to include in a report
plot(p_sp)
```