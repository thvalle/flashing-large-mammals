---
title: "GLMM per art"
author: "Torgeir Holmgard Valle"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    keep_md: true
---

```{r setup}
library(tidyverse)
library(lme4)
library(performance) # diagnostic-plots to check assumptions
library(report)      # Result-summaries in text-format
library(ggeffects)   # Estimated Marginal Means and Marginal Effects from Regression Models
                          # more at: https://strengejacke.github.io/ggeffects/
library(parameters)  # extract model-parameters etc. from (most) models
library(sjPlot)      # parameters + sjPlot probably does a similar and better job than ggeffects
library(see)         # plot-related package from the easystats-verse

# Data drom Data_exploration2_nesting.R
time.dep <- readRDS("timedep.rds")
```

## Purpose

Remaking glmm_sp in a modular fashion, so that changes in the script of one model affects all the rest.

# About the model

### Why GLMM?

Response from a [stackexchange question](https://stats.stackexchange.com/questions/226946/r-lmer-vs-glmer)
about the differences of `lmer` and `glmer`-functions:

>lmer is used to fit linear mixed-effect models, so it assumes that the residual error has a Gaussian distribution. If your dependent variable A is a binary outcome (e.g. a yes/no response), then the error distribution is binomial and not Gaussian. In this case you have to use glmer, which allow to fit a generalized linear mixed-effects model: these models include a link function that allows to predict response variables with non-Gaussian distributions. One example of link function that could work in your case is the logistic function, which takes an input with any value from negative to positive infinity and return an output that always takes values between zero and one, which is interpretable as the probability of the binary outcome (e.g. the probability of the subject responding 'yes').




### Formula
The model formula I will use is $n \sim \ time.deploy\ * flash $ for each species, and my $\alpha = 0.05$.

```{r timedep2}
sp <- c("raadyr", "rev", "hjort", "grevling", "elg", "gaupe", "ekorn", "hare", "maar")
ctrl <- c("Control_1", "Control_2", "Control_3","Control_4")
time.dep2 <- time.dep %>% 
  rename(species = validated_species) %>%  #shortening name
#  filter(species %in% sp) %>% #filtering out species
  # including Control as part of the flash-column, since it differs from flash=0
  mutate(flash = factor(
        ifelse(period %in% ctrl, "Control", flash)),
        week = lubridate::isoweek(date),
        period = factor(period))
time.dep2 <- time.dep2 %>% 
   mutate(flash = fct_relevel(flash, "Control","0","1")) # relevel to make Control the model intercept
levels(time.dep2$flash) <- c("Control", "IR", "LED")
levels(time.dep2$period) <- c("IR_1", "IR_2", "LED_1", "LED_2", "Control_1", "Control_2", "Control_3", "Control_4")

time.dep2$species %>% unique()
```

Not all periods have identical length. Hence, I need to set a maximum length for my period durations. As proposed by Neri, I will calculate the median for white LED-periods and IR-periods, and use the smallest median to shorten all periods overextending that value.

First I'll filter out any periods shorter than 4 days ( _as of 18.02.2021, only 1 period_ ). 
Then I'll cut the duration of all periods overextending the smallest median.


```{r period-median, message=FALSE}
# find median period length
time.period <- time.dep2 %>% group_by(loc, period, flash) %>% 
  summarise(period_length = max(time.deploy))

# checking shortest periods
time.period %>% arrange(period_length) # 1 period (LED) is 0 days

# then merge lengths and filter out period of 0 days
time.dep3 <- time.dep2 %>% left_join(time.period) %>% 
  filter(period_length > 0)

# find median length 
time.period %>% filter(flash == "LED") %>%  
  summary() # median period length 85 days, mean: 84
time.period %>% filter(flash == "IR") %>%  
  summary() # median period length 79 days, mean: 89

# extract lengths of each unique period
h <- time.dep3 %>% group_by(loc, period, period_length, flash)%>% nest() %>% 
  select(!data) 
#extracting median and multiplying by 10, to use in the correctly scaled plot
hh <-       h$period_length[h$flash == "LED"] %>%  median()       # median white LED
hh <- c(hh, h$period_length[h$flash == "IR" ] %>%  median()) * 10 # + median IR
# smallest median 
h <- min(hh)
```


With the updated dataset, the IR median has shifted to 84 days, white LED to 85. 84 is the new trimming value.



```{r period-length, message=FALSE}
# plot periods with median as intercept
p_td <- time.dep3 %>% filter(!period %in% ctrl) %>% 
  ggplot(aes(loc, 10*time.deploy, colour = period, ))  +
  geom_line(aes(linetype = flash),position = position_dodge(width = 1), lineend = "square") +
  coord_flip() + 
  labs(title = "Period lengths per camera",
       x = "Location", y = "Time since deployment",
       caption = "Vertical lines reprecent median period lengths for IR and white LED.\n Data superceding that were trimmed away for the GLMM-modelling.") +
  ggpubr::theme_classic2() #+ theme(legend.position = "right") find way to set legend inside
p_td + geom_hline(aes(yintercept = h), linetype = "dashed",  alpha =.5) +
  geom_hline(aes(yintercept = max(hh)), linetype = "dashed",  alpha =.5) +
  #annotate(geom = "text",x=4, y=h+8.6, label = "- median", size = 3, alpha =.7) +
  scale_y_continuous(breaks = sort(c(0, 50, h, 100, 150))) +
  scale_color_brewer(palette = "Spectral")
# failed attempts that could inspire a better plot later
# p_td + geom_hline(aes(yintercept = h))+ # using median days as intercept 
#        scale_y_continuous(breaks = sort(c(ggplot_build(p_td)$layout$panel_ranges[[1]]$y.major_source, h)))
# geom_text(aes(25, h, label = "median", vjust = -1), nudge_y = 10, show.legend = F)
```

There was an overweight of IR-periods extending past the median line.


```{r period-length-wControl, message=FALSE, warning=FALSE}
# remake plot with Control-group data, faceted
p_td2 <- time.dep3 %>% 
  ggplot(aes(loc, 10*time.deploy, col = period))  +
  geom_line(aes(linetype = period),
    position = position_dodge(width = 1), lineend = "square") +
  coord_flip() +  
  geom_hline(aes(yintercept = h), linetype = "dashed",  alpha =.5) +
  scale_y_continuous(breaks = sort(c(0, 50, h, 100, 150, 200))) +
  facet_grid(rows = "flash", scales = "free_y") +
  labs(#title = "Period lengths per camera",
       x = "Location", y = "Time since deployment",
       caption = "Vertical line reprecents median period length for IR.\n Data superceding that were trimmed away for the GLMM-modelling.")
  

p_td2 + ggpubr::theme_classic2() +
  theme(legend.position = "none", axis.text.y = element_blank(), axis.ticks.y = element_blank()) +
        scale_linetype_manual(values = rep(c("solid","solid"), 4) ) + #option to change to solid,dashed
        scale_color_manual(values = c(rep(c("#74add1","#4575b4"), each = 2), # trt-colr
                                      rep(c("#f46d43","#fdae61"),each = 2) ) ) #ctrl-colr
```



_Lastly, performing the filter:_
```{r time.dep4-filtr}
# filtering out periods longer than (shortest) median length.
time.dep4 <- time.dep3 %>% filter(time.deploy < h/10) # h is normal scale, must be rescaled by /10
                
```


# Modelling

## Roe deer


```{r summary, eval=FALSE}
time.dep4$loc %>% unique() %>% is.na() %>% any() # no NAs in loc
summary(time.dep4) #
```

```{r sp, eval=FALSE}
time_sp <- filter(time.dep4, species %in% sp) #.dep4 = trimmed data
# Model
m_sp  <- lme4::glmer(n.obs ~ time.deploy * flash + # fixed effects
            (1 | loc) + (1 | week), # random effects
            data   = time_sp,
            family = poisson) # poisson family of distributions

# ggpredict is similar to expand.grid
p_sp <- ggeffects::ggpredict(m_sp, terms = c("time.deploy [all]", "flash"))
# Diagnostics
plot(p_sp, add.data = TRUE) + labs(title = "add.data = TRUE")
plot(p_sp, residuals = TRUE) + labs(title = "residuals")
performance::check_model(m_sp) # check assumptions
```


The response variable is a summary of number of events per day. Most days had no roe deer.
In the performance-test for model assumptions _it is clear that some assumptions aren't met._

#### Negative
In the non-normality of resiudals-plot, the residuals skew off from the line when moving towards positive quantiles.
There is _not_ a homogeneity of variance. _Maybe this could be fixed by centering the n.obs-column?_

There appeares to be five influential observations in the Cook's distance-plot, maybe more, as the warning from ggrepel refers to 93 unlabeled data points due to overlaps.

#### Positive
Although the model has an interaction term between flash and time since deployment, the multicollinearity between them is low!
My random effects follows a normal distribution.

#### Concluding
I am not sure about how to make up for breaking these assumptions. For now, I will go on completing models for the rest of the species.

```{r sp-report, eval=FALSE}
# Summary, report, model
summary(m_sp)
r_sp <- report::report(m_sp) # text-summary of my model, to include in a report
para_sp  <- model_parameters(m_sp,   standardize = "refit", two_sd = TRUE, exponentiate = TRUE) 
```

### Model interpretation
The intercept-value is considered significantly negative, which is to say that there were a low chance of detecting any roe deer at an IR-camera the same day I visited the camera.

> I saw a roe deer about to walk by a CT when I came to inspect it. The roe deer saw me and fled, right before it was detected by the camera. Chances are I've scared animals other times as well, but haven't noticed it.

The effect of _Time since deployment_ is non-significant, and $\beta = 0.008$.
That means there is no difference on the baseline detection rate for an IR camera over time (after controlling for seasonal changes). 

For white LED flash  $\beta = 0.170$, meaning that the intercept is slightly higher than for IR, but the difference is non-significant ($p = 0.18$).
However, the detection rate is slightly decreasing the longer the white LED stays, which differs from the IR, _
but the effect is non-significant_ ($p = 0.23$).

#### Hypothesising
If there truly is an effect of the white LED for long periods on the detection rate of roe deer, this effect could in turn account for the different intercept values of IR and flash, as the IR periods often start after a flash period.

Remembering my study design, 20 cameras start with white LED, 20 with IR. _Intercept should be equal_ (1st period).
2nd period; white LED moved, new LED CTs (same intercept), new IR CTs (hypothetical lower intercept due to flash effect).
3rd period; white LED moved, new LED CTs (IR intercept), new IR CTs (hypothetical lower intercept).
4th period;  - -  ||  - -  , new LED CTs (- - | | - - ), new IR CTs (   -  -  |  |  -  -  ).

Which sums up to 3 IR periods where detection rates could start lower than that of white LED. And over time the lack of white LED flash in the new IR sites would account for an _increase_ in detection rates.

The effect would of course vary because some locations experienced _gaps_ due to full SD cards or empty batteries.
<!--_Maybe, after my thesis, I could try to pry out these differences-->

-------------------------------------

#### Update!

After uptaded data from Neri; the effect of flash is now deemed significant!
Still the same pattern with higher intercept and a negative slope along the time axis, which further supports my hypothesising above.
The interaction with time since deployment is, however, still non-significant.
_Now I want to look at a model including the Control-group._

`r sp = "raadyr"`
```{r raadyr, ref.label='sp'}
# filter species
#<<sp>>
```




There are a couple of extreme counts in the Control-group, even after having filtered away all observations with less than a 15 min interval for each species (ie. setting 15 min margin as definition of an event). These extreme counts are skewed to the left which probably will affect the intercept of control quite a bit, but probably won't deem the intercept-value as significant (as these extreme values are outliers).

The homogeneity of variance is still off. It deems on me more and more that this is due to these extreme count-values that is close to time.deploy = 0. _Will it disappear if I divide by the standard deviation?_

The multicollinearity is moderate for the interaction term of time.deploy and flash when the control group is included. Still, the change is small (in my layman eyes), with a increase in bar height from ~ 4 to ~ 6.


```{r raadyr-report, ref.label='sp-report'}
#<<sp-report>>
```





The control intercept is almost on top of the IR-intercept, but it has a more negative trend than the IR-group. After I got updated data and performed the event-filter, the slope of IR changed to a negative trend over time, as well, "removing" any significance from the flash terms. The important thing to note, then, is how small the p-values was, and how easily they turned non-significant.
Looking at the plot, the confidence interval tells us all we need to know, as they almost completely overlap.
The groups are almost identical. The slope of the control group is actually steeper than that of white LED (although only minisculy).
Further, the trend over time with the control-group __should__ be due to chance, _as time.deploy = 0 is seldom the actual day I visited the cameras_. They were visited less often in general, and the breaks leading to time.deploy = 0 are set manually by me, to make period lengths that are similar to those of the IR and white LED group.

### Some parameter-plots from see and effectsize

The CI-plots of effectsize will be included in some form in my thesis. For the equivalence-plot I'm not to sure if I'll use it, but the interpretation is neat with that method. From the bayesian statistics, if a predictor is completely covered by the ROPE-area you can accept the null hypothesis. This is not possible in a frequentist perspective (as my models are), but one could claim _practical equivalence_ if the effect is non-significant AND completely inside the ROPE-interval. Explanations from [Equivalence vignette](https://easystats.github.io/parameters/reference/equivalence_test.lm.html):

>"classic" - The TOST rule (Lakens 2017)
This rule follows the “TOST rule”, i.e. a two one-sided test procedure (Lakens 2017). Following this rule, practical equivalence of an effect (i.e. H0) is rejected, when the coefficient is statistically significant and the narrow confidence intervals (i.e. 1-2*alpha) include or exceed the ROPE boundaries. Practical equivalence is assumed (i.e. H0 accepted) when the narrow confidence intervals are completely inside the ROPE, no matter if the effect is statistically significant or not. Else, the decision whether to accept or reject H0 is undecided.
>"cet" - Conditional Equivalence Testing (Campbell/Gustafson 2018)
The Conditional Equivalence Testing as described by Campbell and Gustafson 2018. According to this rule, practical equivalence is rejected when the coefficient is statistically significant. When the effect is not significant and the narrow confidence intervals are completely inside the ROPE, we accept H0, else it is undecided



```{r parameters}
result <- model_parameters(m_sp) 
plot(result, size_text = 3) + labs(title = paste0(sp, " GLMM parameters") ,
                                    subtitle = ' not standardized ')

plot(para_sp, size_text = 3) + labs(title = paste0(sp, " GLMM parameters") ,
                                    subtitle = 'standardize  = "refit" ')

# default rules, like in bayestestR::equivalence_test()
result <- equivalence_test(m_sp)
plot(result)
result
```


```{r sp-report2}
summary(r_sp)
as.report_table(r_sp)
```


```{r raadyr-objects}
# Storing species-specific objects for later
# Model
m_raa    = m_sp
# ggpredict 
p_raa    = p_sp
# report-object
r_raa    = r_sp
# parameters refit
para_raa = para_sp
```


sp
sp-report
sp-report2
parameters

objects


#### Skrivestopp

-------------------------------------------------------------

## Red Fox

`r sp = "rev"`

```{r rev, ref.label=c('sp','sp-report')}
```
```{r rev2, ref.label=c('sp-report2','parameters')}
```


```{r rev-objects}
# Model
m_rev    = m_sp
# ggpredict 
p_rev    = p_sp
# report-object
r_rev    = r_sp
# parameters refit
para_rev = para_sp
```


```{r knit-exit, eval=FALSE}
knitr::knit_exit() # to exit knitting process here instead of at the document end
```


## Badger

`r sp = "grevling"`

```{r grevling, ref.label=c('sp','sp-report')}
```
```{r grevling2, ref.label=c('sp-report2','parameters')}
```


```{r grevling-objects}
# Model
m_grvl    = m_sp
# ggpredict 
p_grvl    = p_sp
# report-object
r_grvl    = r_sp
# parameters refit
para_grvl = para_sp
```


## Moose

`r sp = "elg"`

```{r elg, ref.label=c('sp','sp-report')}
```
```{r elg2, ref.label=c('sp-report2','parameters')}
```


```{r elg-objects}
# Model
m_elg    = m_sp
# ggpredict 
p_elg    = p_sp
# report-object
r_elg    = r_sp
# parameters refit
para_elg = para_sp
```

## Red deer

`r sp = "hjort"`

```{r hjort, ref.label=c('sp','sp-report')}
```
```{r hjort2, ref.label=c('sp-report2','parameters')}
```


```{r hjort-objects}
# Model
m_hjort    = m_sp
# ggpredict 
p_hjort    = p_sp
# report-object
r_hjort    = r_sp
# parameters refit
para_hjort = para_sp
```


## Lynx

`r sp = "gaupe"`

```{r gaupe, ref.label=c('sp','sp-report')}
```
```{r gaupe2, ref.label=c('sp-report2','parameters')}
```


```{r gaupe-objects}
# Model
m_gaup    = m_sp
# ggpredict 
p_gaup    = p_sp
# report-object
r_gaup    = r_sp
# parameters refit
para_gaup = para_sp
```


# Small species

Added late, because I was unsure about whether it made sense to include them or not.
After having learned about the random effects, I think it does make sense, even though the cameras in my study were set up with the original aim of photo capturing lynx.

## Hare

`r sp = "hare"`

```{r hare, ref.label=c('sp','sp-report')}
```
```{r hare2, ref.label=c('sp-report2','parameters')}
```


```{r hare-objects}
# Model
m_hare    = m_sp
# ggpredict 
p_hare    = p_sp
# report-object
r_hare    = r_sp
# parameters refit
para_hare = para_sp
```


## Red squirrel

`r sp = "ekorn"`

```{r ekorn, ref.label=c('sp','sp-report')}
```
```{r ekorn2, ref.label=c('sp-report2','parameters')}
```


```{r ekorn-objects}
# Model
m_ekorn    = m_sp
# ggpredict 
p_ekorn    = p_sp
# report-object
r_ekorn    = r_sp
# parameters refit
para_ekorn = para_sp
```



## European Pine marten

`r sp = "maar"`

```{r maar, ref.label=c('sp','sp-report')}
```
```{r maar2, ref.label=c('sp-report2','parameters')}
```


```{r maar-objects}
# Model
m_maar    = m_sp
# ggpredict 
p_maar    = p_sp
# report-object
r_maar    = r_sp
# parameters refit
para_maar = para_sp
```



----------------------------------------------

# All models


## Parameter-table

```{r model-report}
library(xtable)  # To make a latex-table for the thesis
para_raa  <- para_raa %>% 
  add_row(Parameter = "Roe deer", .before = 1) # adds a row for species name in the resulting table
para_rev  <- para_rev   %>% add_row(Parameter = "Red fox",  .before = 1)
para_grvl <- para_grvl  %>% add_row(Parameter = "Badger",   .before = 1)
para_elg  <- para_elg   %>% add_row(Parameter = "Moose",    .before = 1)
para_hjort<- para_hjort %>% add_row(Parameter = "Red deer", .before = 1)
para_gaup <- para_gaup  %>% add_row(Parameter = "Lynx",     .before = 1)
para_hare <- para_hare  %>% add_row(Parameter = "Hare",     .before = 1)
para_maar <- para_maar  %>% add_row(Parameter = "European Pine Marten", .before = 1)
para_ekorn<- para_ekorn %>% add_row(Parameter = "Red squirrel", .before = 1)

# bind tables together
para_all <- bind_rows(para_raa, para_rev, para_grvl,para_elg,para_hjort,para_gaup,para_hare,para_maar,para_ekorn) %>%
  insight::format_table(ci_brackets = c("(", ")")) %>% #prettier ci-brackets
  select(!df) # remove the df-column, containing "Inf" for every species

# save as latex-table in the Thesis folder
print(xtable(para_all, type = "latex"), include.rownames = F,
      file = "../Thesis/tex/tab/parameters.tex")

# unable to find a automated way of removing \end{table}
```

## Joint forest-plots

Plots divided into size-based groups of three x three species.
Thus, ungulates are one group, the largest carnivores are one, and the smallest three form the most mixed group of hare, squirrel and pine marten 

```{r mod-plot}
sjPlot::plot_models(m_rev, m_grvl, m_gaup, spacing = 0.4, legend.title = "Species",
                    m.labels = c("Badger","Lynx","Red fox"))
sjPlot::plot_models(m_raa, m_elg, m_hjort, spacing = 0.4, legend.title = "Species",
                    m.labels = c("Roe deer","Moose","Red deer"))
sjPlot::plot_models(m_ekorn, m_hare, m_maar, spacing = 0.4, legend.title = "Species",
                    m.labels = c("Hare","Pine marten","Red squirrel"))
```

## Predict-plots

ggpredict-plots for marginal effects.

```{r mod-predict}
p1 <- p_raa   %>% plot() + labs(title = "", subtitle = "Roe deer" )
p2 <- p_rev   %>% plot() + labs(title = "", subtitle = "Red fox " )
p3 <- p_grvl  %>% plot() + labs(title = "", subtitle = "Badger "  )
p4 <- p_elg   %>% plot() + labs(title = "", subtitle = "Moose "   )
p5 <- p_hjort %>% plot() + labs(title = "", subtitle = "Red deer" )
p6 <- p_gaup  %>% plot() + labs(title = "", subtitle = "Lynx "    )
p7 <- p_hare  %>% plot() + labs(title = "", subtitle = "Hare"    ) 
p8 <- p_maar  %>% plot() + labs(title = "", subtitle = "European Pine marten")
p9 <- p_ekorn %>% plot() + labs(title = "", subtitle = "Red squirrel"    )
library(cowplot)
# plot grid     
# # script from https://wilkelab.org/cowplot/articles/shared_legends.html
prow <- cowplot::plot_grid(
  p1 + theme(legend.position="none"),
  p2 + theme(legend.position="none"),
  p4 + theme(legend.position="none"),
  p5 + theme(legend.position="none"),
  p6 + theme(legend.position="none"),
  p7 + theme(legend.position="none"),
  p8 + theme(legend.position="none"),
  p9 + theme(legend.position="none"),
  align = 'vh',
  labels = c("A", "B", "C","D","E","F","G","H","I"),
  hjust = -1,
  nrow = 3)

# # extract the legend from one of the plots
# legend <- get_legend(
#   # create some space to the left of the legend
#   p1 + theme(legend.box.margin = margin(0, 0, 0, 12))
# )
# 
# # add the legend to the row we made earlier. Give it one-third of 
# # the width of one plot (via rel_widths).
# plot_grid(prow, legend, rel_widths = c(3, .4))

# extract a legend that is laid out horizontally
legend_b <- get_legend(
  p1 + 
    guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

# add the legend underneath the row we made earlier. Give it 10%
# of the height of one plot (via rel_heights).
plot_grid(prow, legend_b, ncol = 1, rel_heights = c(1, .1))
```



## Model comparison-plots

Whichs species' detection rates was best explained by the my model formula?

```{r mod-comparisons}
m_compare <- compare_performance(m_raa,m_rev,m_grvl,m_elg,m_hjort,
                                 m_gaup, m_hare, m_ekorn, m_maar,
            metrics = "common", rank=T) # "common" will compute AIC, BIC, R2, ICC and RMSE
m_compare
m_compare %>% plot() #A `range` must be provided for data with only one observation.
# test_performance(m_raa,m_rev,m_grvl,m_elg,m_hjort,m_gaup) #models don't have the same response variable, 
# which is because they are different subsets of each other
```


```{r mod-checks}
check_overdispersion(m_raa)   # No overdispersion detected
check_overdispersion(m_rev)   # -     -    | |    -    -
check_overdispersion(m_grvl)  # -     -    | |    -    -
check_overdispersion(m_elg)   # -     -    | |    -    -
check_overdispersion(m_hjort) # -     -    | |    -    -
check_overdispersion(m_gaup)  # -     -    | |    -    -
check_zeroinflation(m_raa)   # Model seems ok, ratio of observed and 
check_zeroinflation(m_rev)   #    predicted zeros is within the tolerance range.  
check_zeroinflation(m_grvl)  #          -     -    | |    -    -   
check_zeroinflation(m_elg)   #          -     -    | |    -    -   
check_zeroinflation(m_hjort) #          -     -    | |    -    -  
check_zeroinflation(m_gaup)  #          -     -    | |    -    -
check_singularity(m_raa)   # FALSE
check_singularity(m_rev)   #--||--
check_singularity(m_grvl)  #--||--   
check_singularity(m_elg)   #--||--   
check_singularity(m_hjort) #--||--  
check_singularity(m_gaup)  #--||--
```
















--------------------------------------------


# Hare, deer and squirrelywhere (and pine marten) 

Blueprint for other species in chunk below:



<!--`r sp = "xx"`-->

```{r xx, ref.label=c('sp','sp-report'), eval=FALSE}
```
```{r xx2, ref.label=c('sp-report2','parameters'), eval=FALSE}
```


```{r xx-objects, eval=FALSE}
# Model
m_xx    = m_sp
# ggpredict 
p_xx    = p_sp
# report-object
r_xx    = r_sp
# parameters refit
para_xx = para_sp
```


----------------------------------------------

# SessionInfo

```{r sessionInfo}
sessionInfo()

report_parameters(sessionInfo()) # output to include in Appendix
```

