---
title: "Survival modelling"
author: "Torgeir"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: github_document
---

```{r setup, include=FALSE, warning=FALSE,message=FALSE, echo=TRUE,}
# 
# knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# options(tibble.print_min = 5)

library(tidyverse)  # entering the tidyverse
library(tidymodels) # and bringing the model-toolbox
library(lubridate)  # lubricating the handling of dates
library(survival)   # the original survival-package
library(survminer)  # a plot-package for ggplot integration
library(vip)        # for variable importance plots
library(pander)     # for prettier outputs of summaries and tables etc.
library(report)     # for reporting test-statistics 
library(equatiomatic) # Model formula displayer in RMarkdown

# Analysis - Survival. Including spatial covariates 
covs<-readRDS("CTloc_covs.rds") %>% select(-geometry) %>% 
  as.data.frame() %>% # Chaning class to data.fram and not a sf data.frame
 mutate(house_d2_ln = ifelse(house_d2 > 0, log(house_d2), 0),
        field_d2_ln = ifelse(field_d2 > 0, log(field_d2), 0),
        elev_ln = log(elev)) 
obs <- readRDS("obs_tte5.rds")%>% # obs prepared for survival analysis (Time_to_Event_Torgeir5.R, line 133)
  rename(species = validated_species) %>% 
  merge(covs, by.x="loc", by.y="LokalitetID", all.x=TRUE, all.y=FALSE) %>% 
  left_join(readRDS("habitat.rds"), by = "loc") 
# names(covs)
# names(obs)
# unique(obs$house_d2_ln)
# unique(covs$LokalitetID)
# unique(obs$loc)
```

# Purpose of this notebook
Transporting Neri's survival analysis skript into a Rmd-notebook, as for me to be able to write down thoughts and ideas along the way while learning more about R and analysing _my_ data.

This is not written as a lab-notebook from day to day, but rather as a gross layout to what my results-section could end up looking like, or at least a "behind the scenes"-approximation.

I'm also considering to implement the survival analysis into the tidymodels framework, as I like their approach of connecting different modelling-packages into one identical syntax. Thus it is easier to try out different types of models (lm, glm, glmm, etc.).
Also, it seems I can make general models for all my species in conjunction that way, following the roadmap layed out by Hadley Wickham in [R for Data Science - Chapter 25: Many Models](https://r4ds.had.co.nz/many-models.html).
However, my attempts have not succeeded as of yet.

<!-- Comments look like this, instead of the LaTeX % -->
<!--  rmarkdown::render("surv_in_process.Rmd", output_format = "odt_document") 
for odt. word-document -->
<!-- output:
  html_document:
    code_folding: hide -->
<!-- github_document -->

------------------------------------------

# Setting up the data

```{r skim}
obs %>% 
  skimr::skim(species, period) 
```


First, I'll filter out the species I will focus on. As the cameras were set up to detect lynx, I will filter out species that are significantly smaller. Squirrel and hare are examples of species that can't be expected to get detected every time they pass close to the expected travelling route, due to the average height of the cameras, and that they are not angled towards the ground.

In addition I filter out non specific groups (e.g. birds), infrequent sightings (i.e. < 50), and irrelevant groups (cattle, vehicles, humans). However, the "irrelevant" groups could be interesting to come back to later, to see if their presence have predictive power in my models.
```{r sp-focus, echo=TRUE}
fjern <- c("nothing","hund", "menneske", "kjoeretoey", "motorsykkel", "sykkel", "ukjent", "null",
           "sau", "ku", "fugl", "skogshons", "smagnagere", "andre_maardyr", "andre_pattedyr") # uninteresting or too general groups
passes <- obs %>% group_by(species) %>% 
  summarise(count = n(),  
            period = period, flash = flash) %>% 
  filter(!is.na(species), !(species %in% fjern))
  ggplot(passes) +
  geom_bar(aes(reorder(species, count, FUN = mean)), position = "dodge") +  # reorders by mean count
  geom_hline(yintercept = 50) + coord_flip() # flip the axes
# removing small mammals
small <- c("maar", "ekorn", "hare")
p_sp_focus <- passes %>% 
  filter(count > 50, !species  %in% small) %>%  
  ggplot(aes(reorder(species, count, FUN = mean))) + coord_flip()
p_sp_focus + geom_bar(aes(fill = flash),position = "dodge") + geom_hline(yintercept = 50)
```

Having filtered out most sightings, we are left with the most common, large mammals. There are very few sightings of lynx when divided by times it was and wasn't flashed by a white LED. 
For the rest of the species in this plot, we can rest assured that we have a lot of datapoints, and that the species are large enough to be photo captured every time they pass the camera by the expected route.


# Modelling

### Baseline hazard function

The baseline hazard function $H_0(t)$ is the hazard at time $t$ when all predictors equals to zero.
You can think about the $H_0(t)$ being the intercept, although this is not strictly true. 
That is because in reality, $H_0(t)$ varies over time, and we can never know its true value.
However, we can calculate the hazard ratio between groups. We will never know a true hazard for any given group at a given time,
because we lack the knowledge of the shifting baseline, but we can know the relative hazard between groups.

In other words, for my case, I do not know the true probability (hazard) for any given species to get photo-captured by any of the
cameras in my study. Nor can I find it out, as this truly is an ever changing value. Still, I can measure the relative difference
in frequencies between the groups equipped with a white LED flash, and the groups only equipped with IR flash.

Ratios must stay constant over time, ie. if group B has twice the hazard of group A at time $t$, the assumption is that this relationship will stay that way at time $t + 1$. 
In other words, as I assume different species will have different reactions to the white LED, I cannot estimate the Hazard ratio between species.
At least I think I can't, considering for example if a badger is indifferent to the white LED, his ratio to any other _reacting_ species will be constantly changing.

### Survival plot of roe deer
First I make a mod0 only containing _loc_ as a random factor on intercept, and _flashed_ as a predictor.
I will also start by plotting a survival plot with these predictors

```{r survplot0}
sp = "raadyr"
# Cumulative hazards - Control included
obs_sp <- obs %>% filter(species %in% sp ) %>% 
  mutate(flash = ifelse(period == "Control", 3, flash) )
fit <- survfit(Surv(t.diff, event, type = "right") ~ flash + (1|loc), 
  data = obs_sp)
ggsurvplot(fit, data = obs_sp, title = "roe deer - cumulative hazards w/Control group", 
          break.time.by = 20, ggtheme = theme_minimal(),
          censor.shape = "|", censor.size = 3, fun = "cumhaz",
          legend.labs =  c("IR","white LED","Control"),
          ncensor.plot = T, ncensor.plot.height = 0.25)

# Survival probabilty against time. - Control excluded
obs_sp <- obs %>% filter(species %in% sp & !period == "Control") # filtering out control + keeping only sp
fit <- survfit(Surv(t.diff, event, type = "right") ~ flashed + (1|loc), 
  data = obs_sp)
ggsurvplot(fit, data = obs_sp, title = "roe deer", 
          risk.table = T, break.time.by = 20, ggtheme = theme_minimal(),
          censor.shape = "|", censor.size = 3,
          legend.labs =  c("IR","white LED"),
          tables.height = 0.2, tables.theme = theme_cleantable())
ggsurvplot(fit, data = obs_sp, title = "roe deer",
          risk.table = T, break.time.by = 10, ggtheme = theme_minimal(),
          conf.int = T, xlim = c(0,50), censor.shape = "|", censor.size = 3,legend.labs =  c("IR","white LED"),
          tables.height = 0.2, tables.theme = theme_cleantable()
          #cumcensor = T
)

# fun = "event" plots cumulative events (f(y) = 1-y), 
# "cumhaz" plots the cumulative hazard function (f(y) = -log(y)), and 
# "pct" for survival probability in percentage
```

Three different survival plots of the roe deer. Including the confidence intervals shows that the IR curve is almost constantly enveloped in the LED-curve confidence interval.

When the confidence intervals are included in the plot, the white LED CI overlaps the IR curve almost constantly.
Therefore it doesn't seem to be a large effect of our flash.
Additionally, it is interesting to see that the effect is of the blits is luring, rather than scaring.
The survival time is shorter for white LED, which means that roe deer either gets drawn to the camera, or at least that their detection rate goes up.

The curves seem to cross eachother at a couple of points. 
Am I breaking the assumption of proportional hazards?
To find out I will fit the model in a coxph-object, and look at the summaries, before I'll perform a Schoenfeld test on the residuals.

_Breaking down control-group lengths into shorter periods would be interesting, making the time scale proportional as well, and thereby increasing the sample size per time_

### Model 0 | ~flashed
```{r mod0}
mod0 <- coxph(Surv(t.diff, event, type = "right") ~ flashed + (1|loc), 
  data = obs_sp)                                            #  cleaner code with a temporary obs_sp
summary(mod0) 
class(obs$loc)
```

The Cox regression results can be interpreted as follow:



Hazard ratios. The exponentiated coefficients (exp(coef) = exp(-0.53) = 0.59), also known as hazard ratios, give the effect size of covariates. For example, being female (sex=2) reduces the hazard by a factor of 0.59, or 41%. Being female is associated with good prognostic.


_Global statistical significance of the model. Finally, the output gives p-values for three alternative tests for overall significance of the model: The likelihood-ratio test, Wald test, and score logrank statistics. These three methods are asymptotically equivalent. For large enough N, they will give similar results. For small N, they may differ somewhat. The Likelihood ratio test has better behavior for small sample sizes, so it is generally preferred._

```{r diagnostics0}
# 1 (hazard ratio of 1) the coeffecient estimate is significant.
ggforest(mod0, data = obs_sp)

# Test the proportional hazards assumption
d.mod0 <- cox.zph(mod0)  
d.mod0 # Non-significant --> we can assume proportional hazards.
summary(fit)$table

# Can also look at Schoenfeld residuals, there should be no
# pattern with time
ggcoxzph(d.mod0)
```

The first plot represent the confidence interval visually, where it is easy to spot the overlap of a Hazard ratio $= 1$.
Then, testing the proportional hazards with the cox.zph()-function. As there is only one predictor ( _flashed_ ), the individual and global test is the same. The score is non-significant ($p = 0.16$), so we can assume proportional hazards. 
Also, looking at the plot of the residuals, we can see the scores repeated, and the visual representation of residuals. 
No residuals cross the dotted line.

Interesting to note on the summary(fit)-table are the standar error values. The white LED curve's se:`r summary(fit)$table[12]` is nearly twice as large as that of the IR:`r summary(fit)$table[11:12]`.




## Models with random effect for location


### Model 1 |  ~ )

```{r mod2-house}


#ggforest(mod2a, data = obs_sp)

ranef(mod2a)

exp(7.640597e-01)

# Test the proportional hazards assumption
d.mod2a <- cox.zph(mod2a)  
d.mod2a # Non-significant --> we can assume proportional hazards.

# Can also look at Schoenfeld residuals, there should be no
# pattern with time
ggcoxzph(d.mod2a, font.main = 12, ggtheme = theme_classic2())
```









So what am I really testing when I'm doing a survival analysis?
I'm testing whether or not the survival curves are significantly different from each other.
If it is, the summary-output of a model will show a p-value ( Pr(>|z|) ) lower than 0.05, and the lower and upper .95 interval should not contain the value _**1**_.

The coefficient of _flashed_ for roe deer has a $Pr(>|z|) = 0.106$ and the .95 confidence interval is $0.977$ to $1.273$.
In other words, the null hypothesis that there is no difference in detection rates between sites where animals were flashed by a white LED and sites where they weren't, cannot be rejected.
The difference that showed up in the two curves could just as likely be due to chance


```{r survplot-habitat}
sp = "raadyr"
obs_sp <- obs %>%  # remaking obs_sp, to include all 6 species
  filter(species %in% sp & !period == "Control")

# Survival probabilty against time.
fit<-survfit(Surv(t.diff, event, type="right") ~ flashed +  habitat,
             data=obs_sp)

ggsurv <- ggsurvplot(fit, data = obs_sp, title = "white LED flash: dotted lines",
                     #fun = "cumhaz", conf.int = TRUE,
                     risk.table = T, #risk.table.height = "none",
                     risk.table.y.text.col = T,# colour risk table text annotations.
                     risk.table.y.text = FALSE,# show bars instead of names in text annotations
                     ggtheme = theme_minimal(),  
                     censor.shape = "|", censor.size = 3,
                     xlim = c(0,120),linetype = rep(c(1,2), each = 6),
                    # legend.labs =  c("white LED", "IR"),
                     tables.height = 0.2, tables.theme = theme_cleantable())
curv_facet <- ggsurv$plot + facet_wrap( ~ habitat) #+ theme(legend.position = "none")
curv_facet + theme(legend.position = "none")
# ggsurv$table + facet_grid( ~ species, scales = "free") +
#   theme(legend.text = element_text(size = 6),legend.title = element_blank(),
                  # legend.key.size = unit(5, 'mm'))
```




-----------------------------------------------

### ANOVA test of 
Unsure as to whether this can be used, but I'll keep it included in the document.
```{r ANOVA-raadyr, eval=FALSE}
sp = "raadyr"
obs_aov <- obs %>% group_by(loc, period) %>% 
  filter(species %in% sp) %>% 
  summarise(sum_events = sum(event)) # to get a continuous distribution
res_aov <- aov(sum_events ~ period, data = obs_aov)

par(mfrow = c(1, 2)) # combine plots

# histogram
hist(res_aov$residuals)

# QQ-plot
library(car)
qqPlot(res_aov$residuals,
  id = FALSE # id = FALSE to remove point identification
)

```


-----------------------------------------------






After having compared the two hazards, ie. calculated a hazard ratio, I should check for confounding factors.
To do that, I will make new models without the _flashed_-factor, only including variables about the micro habitat in general. 
Shaving away non-significant variables, and finding the best model with the AIC model selection. Then, I will add the _flashed_-factor as a predictor to that model, checking for interactions, and see whether the flash has any predicitive power on the residuals.

In other words, I will remove the variance that can be explained by trail type etc. first.





Remembering my own question as stated in the intro:

> In this study, I will attempt to quantify how the usage of white LED flash affects the detection rate of the most common large mammal species in the area and whether this effect correlates with other factors [such] as urbanisation.

**My thoughts about the distance to forest road variable**
>Forest roads are absolutely a factor of human interference or something like that, but is not exactly what I'm getting at with urbanisation. Also, forest roads are known to attract many species [citation?] and are therefore used actively in camera trapping studies, my own included.
So, including closeness to forest roads can probably account for some "attraction" to camera sites, or rather, higher detection frequencies. 

Having obtained the micro habitat-column, I now have a better predictor for the attractiveness these trails represent.
I coul try to make it the trail-types into a continuous variable with forest road being the highest value, and wildlife trail the lowest, but I'm not sure that would represent a true relationship between the factors.
At least, mod1 shows the relationship I had suspected, but not all of the factors are significant, so I should remove some.

**My thoughts about the distance to nearest house variable**
>On the other hand, distance to house is closer to my urbanisation statement, and is somewhat more of what I had in mind when articulating it.
Specifically, I was thinking about sources to Artificial Light At Night (ALAN), as a possible predictor for how animals react to white LED flash.
Proximity to houses is a somewhat good proxy for that, but still, I'll be missing the ALAN from other types of infrastructure, such as illuminated public roads, and heavily trafficked roads in general.

Just thinking about my distance to house-variable, and what it represents, the way it is used in the model right now, is probably not what I intend.

I don't expect an animal's reaction to be linear with the distance to a house.
Rather, I expect it to be exponentially larger, the closer the animal gets, ie. the closer the camera's position is to a house, as that is where I observe the animals.
Worded differently, I don't think the difference of 1km and 3km to the nearest house will affect a roe deer, 
as much as the difference of 50m and 500m will.
Therefore I need to log transform the covariate, and in doing so I have to be careful with 0-values.
Many cameras are positioned on or directly next to a forest road, and log transforming these values would create infinite-values. 



### Model 2 |  ~habitat and log(house_d2)

```{r mod2}
sp = "raadyr"
obs_sp <- obs %>%  # remaking obs_sp, to include the new covariates
  filter(species %in% sp & !period == "Control")

mod2<-coxph(Surv(t.diff, event, type="right")~ habitat + house_d2_ln +
              (1|loc), data=obs_sp)
summary(mod2)
ggforest(mod2, data = obs_sp)

# Test the proportional hazards assumption
d.mod2<-cox.zph(mod2) # Non-significant --> we can assume proportional hazards.
d.mod2

# Can also look at Schoenfeld residuals, there should be no pattern with time
ggcoxzph(d.mod2)

```

Closeness to house, when log-transformed, is in fact highly significant as a negative predictor.
It's standard error also appears to sligtly increase. Not surprisingly, since a much smaller digit now represents large distance-values.
The standard error of the habitat-factors seems to have slightly decreased as well, and they have turned more signicant in predicting the remaining variation.

All paths are predicting an attractiveness to detections, including canyon, which often will serve as a tract for animals.
Also, canyons can sometimes be a secluded area with few humans seeking it out.

This is also true for cliffs.
In some way they can be even more secluded from nearby humans, and therefore attractive for animals.
A cliff's distance to a nearby house will also be misrepresented by not including elevation, and potentially breaking the overall pattern of the distance to house-predictor.
Concluding, cliffs are attractive in their seclution, but not easily climbed by roe deer, and thus could be a negative predictor as well.

As cliffs are the only non-significant predictor, I will remove it from the next model.


**old statement when flashed was included in early models**
>The CI of the flashed variable has shifted ever so slightly, now including a Hazard ratio of 1. This model also leaves flash accounting for a positive trend in survival, ie. more frequent redetection of roe deer, but the effect doesn't explain a significant amount of the variation left after considering the other variables.


```{r mod3}
# Setting up model to test if the effect of flash is dependent on distance to house
mod3<-coxph(Surv(t.diff, event, type="right")~flashed * house_d2_ln + habitat,
            (1|loc), data=obs_sp)
summary(mod3)
ggforest(mod3, data = obs_sp)

# Test the proportional hazards assumption
d.mod3<-cox.zph(mod3) # Non-significant --> we can assume proportional hazards.
d.mod3

# Can also look at Schoenfeld residuals, there should be no pattern with time
ggcoxzph(d.mod3,font.main = 12, ggtheme = theme_classic2()) #caption = "Caption goes here"
```



The Global Schoenfeld test has a dangerously low p-value ($p = 0.06$), but it is still insignificant, and we may assume - carefully - proportional hazards.
Looking at the plots for flashed and flashed:house_d2_ln there are some outliers surpassing the dashed line. However, the Schoenfeld Individual Tests are all insignificant.

Interesting to note, is that the flashed effect increases wildly in it's confidence interval, leaving the house_d2_ln variable seeming diminished in it's variation / CI.
Importantly, though, there is no significance in the interaction between flash and distance to house.

```{r mod4}
# Setting up model to test if the effect of flash is dependent on distance to house
mod4 <- coxph(Surv(t.diff, event, type="right") ~ flashed * house_d2 +
                forestroad_d2_ln, data=obs_sp)
summary(mod4)
ggforest(mod4, data = obs_sp)

# Test the proportional hazards assumption
d.mod4<-cox.zph(mod4) # Non-significant --> we can assume proportional hazards.
d.mod4

# Can also look at Schoenfeld residuals, there should be no pattern with time
ggcoxzph(d.mod4,font.main = 12, ggtheme = theme_classic2()) #caption = "Caption goes here"
```

Reverting the house_d2 variable to it's natural form ends up violating the global Schoenfield test (p:0.0067 !)

```{r mod5}
# Setting up model to test if the effect of flash is dependent on distance to house
mod5 <- coxph(Surv(t.diff, event, type="right") ~ flashed * forestroad_d2_ln +
                 house_d2_ln, data=obs_sp)
summary(mod5)
ggforest(mod5, data = obs_sp)

# Test the proportional hazards assumption
d.mod5<-cox.zph(mod5) # Non-significant --> we can assume proportional hazards.
d.mod5

# Can also look at Schoenfeld residuals, there should be no pattern with time
ggcoxzph(d.mod5,font.main = 12, ggtheme = theme_classic2()) #caption = "Caption goes here"
```

The same thing happens when checking for an interaction between the log-transformed distance to forestroad-variable. The interaction seems to violate the individual test, but the model all together completely fails the global test.
Interesting to note how the predicted effect of the flash suddenly shifts to being negative!

Let's see what happens using the normal distance to forestroad covariate:


```{r mod6}
# Setting up model to test if the effect of flash is dependent on distance to house
mod6 <- coxph(Surv(t.diff, event, type="right") ~ flashed * forestroad_d2 +
                 house_d2_ln, data=obs_sp)
summary(mod6)
ggforest(mod6, data = obs_sp)

# Test the proportional hazards assumption
d.mod6<-cox.zph(mod6) # Non-significant --> we can assume proportional hazards.
d.mod6

# Can also look at Schoenfeld residuals, there should be no pattern with time
ggcoxzph(d.mod6,font.main = 12, ggtheme = theme_classic2()) #caption = "Caption goes here"
```
Now, the individual test for the forestroad_d2 variable fails. The interaction does not fail, although the global test fails again, just not that strongly.

Something does seem to happen when flash is considered in conjunction with a _"luring"_ or attractive variable. 
There is something strange going on with the distance to forestroad-variable, so maybe a variable for trail type at the camera station would be a better fit. Strangely, only 3 locations are considered to be on a forestroad, which surprises me. I remember there to be more. At least there are more of tractor roads, and none of the "claimed" forest roads are in any way highly trafficked.

One way to extract a better forest road-variable could be to generate it from the species variable  (eg. __species %in% c("kjoeretoy", "motorsykkel", etc)__). 


## Micro habitat covariate!

```{r micro-habitat}
habitat <- readRDS("habitat.rds")
# table of habitat types on locations in obs
habitat %>% 
filter(loc %in% obs$loc) %>% 
group_by(habitat) %>% summarise(n = n()) %>% arrange(desc(n))

# join habitat-col with obs-object
obs <- obs %>%
  left_join(habitat, by = "loc")
# filtering out species
sp = "raadyr"
obs_sp <- obs %>%
  filter(species %in% sp)
# Setting up model to test if the effect of flash is dependent on distance to house
mod7 <- coxph(Surv(t.diff, event, type="right") ~ flashed + habitat +
                 house_d2_ln, data=obs_sp)
summary(mod7)
ggforest(mod7, data = obs_sp)

# Test the proportional hazards assumption
d.mod6<-cox.zph(mod7) # Non-significant --> we can assume proportional hazards.
d.mod6

# Can also look at Schoenfeld residuals, there should be no pattern with time
ggcoxzph(d.mod6,font.main = 12, ggtheme = theme_classic2()) #caption = "Caption goes here"
```


# Testing the models
## AIC-test
The best-fit model according to AIC is the one that explains the greatest amount of variation using the fewest possible independent variables.

[some tips on aic-referring in method section](https://www.scribbr.com/statistics/akaike-information-criterion/)
```{r AIC_roe}

# Which of the four different models have the lowest AIC?
mod.sel<-AIC(mod0,mod1,mod2,mod3,mod4,mod5,mod6,mod7)
mod.sel$d.AIC<-mod.sel$AIC-min(mod.sel$AIC)
mod.sel[order(mod.sel$d.AIC),]

# mod1$formula
# What is your conclusion? 
```
The AIC score determines model 1 as the best model, excluding the two last models violating the assumption of proportional hazards.
Model 1 was the model with the raw distance to feature-covariates. However, the other models are close on the score level, and should not be dismissed completely.
Maybe different transformations could fit the data better? At least, it is interesting to note that mod3, that had interaction with house_d2 scored on level with mod2 without an interaction.
The score signifies that the model has a better fit, and that the better fit is strong enough to be worth the penalty for a more complicated model!

And, maybe the forest road covariate isn't the best predictor as only three cameras seem to be classified as on a forest road.

`r mod1$formula ;mod1$coefficients`



## Likelihood ratio test
Then, enter the _likelihood ratio test_. I'll use it to test if the full model is significantly better than the reduced model
$H_0$: no difference between models
$H_1$: the full model explains more (larger predictive power)
$^Gstat$ follows a $x^2$-distribution where df = k
P>|chi|:  if significant (<0.05), then $H_1$ is our model


# Repeating for the other species

I haven't spent much time here, as I've tried to find a cleaner approach with tidymodels, but finally gave up.

Firstly, here's a survival plot of all 6 species. 

```{r survplot-all}
sp = c("elg","hjort","grevling","gaupe", "rev", "raadyr")
obs_sp <- obs %>%  # remaking obs_sp, to include all 6 species
  filter(species %in% sp & !period == "Control")

# Survival probabilty against time.
fit<-survfit(Surv(t.diff, event, type="right") ~ flashed +  species,
             data=obs_sp)

ggsurv <- ggsurvplot(fit, data = obs_sp, title = "white LED flash: dotted lines",
                     #fun = "cumhaz", conf.int = TRUE,
                     risk.table = T, #risk.table.height = "none",
                     risk.table.y.text.col = T,# colour risk table text annotations.
                     risk.table.y.text = FALSE,# show bars instead of names in text annotations
                     ggtheme = theme_minimal(),  
                     censor.shape = "|", censor.size = 3,
                     xlim = c(0,120),linetype = rep(c(1,2), each = 6),
                    # legend.labs =  c("white LED", "IR"),
                     tables.height = 0.2, tables.theme = theme_cleantable())
curv_facet <- ggsurv$plot + facet_wrap( ~ species) #+ theme(legend.position = "none")
curv_facet + theme(legend.position = "none")
# ggsurv$table + facet_grid( ~ species, scales = "free") +
#   theme(legend.text = element_text(size = 6),legend.title = element_blank(),
                  # legend.key.size = unit(5, 'mm'))
```

For all species, the survival time is shorter in the periods with a white LED flash, though, as glimpsed by the roe deer model 5 and 6, there could be something else going on.
The lynx curves are constantly crossing each other, which is probably due to the low number of sightings.

Also. the plot would benefit from having a fixed colour for flash/no flash, but I haven't figured that part out yet.


Then I've remade the mod0 and mod5 for all the remaining species.
On the complex models, the Schoenfeld test doesn't fail for fox, moose and red deer.
When it fails for badger and lynx, it is for differing reasons, highlighting the need for individual models when including covariates.



### Fox
```{r mod0-rev}
sp = "rev"
# Fitting model with spatial covariates
obs_sp <- obs %>%  # remaking obs_sp, to include the new covariates
  filter(species %in% sp & !period == "Control")

# Example with distance to forest roads and houses
mod0_rev<-coxph(Surv(t.diff, event, type="right") ~ flashed,
                data=obs_sp)
summary(mod0_rev)
ggforest(mod0_rev, data = obs_sp)

# Test the proportional hazards assumption
d.mod0_rev <- cox.zph(mod0_rev)  
d.mod0_rev 
ggcoxzph(d.mod0_rev, font.main = 12, ggtheme = theme_classic2())
```



```{r mod5-rev}
# Example with distance to forest roads and houses
mod5_rev<-coxph(Surv(t.diff, event, type="right") ~ flashed *
               forestroad_d2_ln + house_d2_ln, data=obs_sp)
summary(mod5_rev)
ggforest(mod5_rev, data = obs_sp)

# Test the proportional hazards assumption
d.mod5_rev <- cox.zph(mod5_rev)  
d.mod5_rev 
ggcoxzph(d.mod5_rev, font.main = 12, ggtheme = theme_classic2())
```

```{r mod7-rev}
sp="rev"
obs_sp <- obs %>%
  filter(species %in% sp)
# Setting up model to test if the effect of flash is dependent on distance to house
mod7 <- coxph(Surv(t.diff, event, type="right") ~ flashed + habitat +
                 house_d2_ln, data=obs_sp)
summary(mod7)
ggforest(mod7, data = obs_sp)

# Test the proportional hazards assumption
d.mod6<-cox.zph(mod7) # Non-significant --> we can assume proportional hazards.
d.mod6

# Can also look at Schoenfeld residuals, there should be no pattern with time
ggcoxzph(d.mod6,font.main = 12, ggtheme = theme_classic2()) #caption = "Caption goes here"

```



### Badger
```{r mod0-grevling}
# sp = c("elg","hjort","grevling","gaupe")
sp = "grevling"

# Fitting model with spatial covariates
obs_sp <- obs %>%  # remaking obs_sp, to include the new covariates
  filter(species %in% sp & !period == "Control")

# Example with distance to forest roads and houses
mod0_grevling<-coxph(Surv(t.diff, event, type="right") ~ flashed, data=obs_sp)
summary(mod0_grevling)
ggforest(mod0_grevling, data = obs_sp)

# Test the proportional hazards assumption
d.mod0_grevling <- cox.zph(mod0_grevling)  
d.mod0_grevling 
ggcoxzph(d.mod0_grevling,font.main = 12, ggtheme = theme_classic2())
```
```{r mod5-grevling}
# Example with distance to forest roads and houses
mod5_grevling<-coxph(Surv(t.diff, event, type="right") ~ flashed *
              forestroad_d2_ln+ house_d2_ln, data=obs_sp)
summary(mod5_grevling)
ggforest(mod5_grevling, data = obs_sp)

# Test the proportional hazards assumption
d.mod5_grevling <- cox.zph(mod5_grevling)  
d.mod5_grevling 
ggcoxzph(d.mod5_grevling,font.main = 12, ggtheme = theme_classic2())
```

### Moose
```{r mod0-elg}
# sp = c("elg","hjort","grevling","gaupe")
sp = "elg"
# Fitting model with spatial covariates
obs_sp <- obs %>%  # remaking obs_sp, to include the new covariates
  filter(species %in% sp & !period == "Control")

# Example with distance to forest roads and houses
mod0_elg<-coxph(Surv(t.diff, event, type="right") ~ flashed , data=obs_sp)
summary(mod0_elg)
ggforest(mod0_elg, data = obs_sp)

# Test the proportional hazards assumption
d.mod0_elg <- cox.zph(mod0_elg)  
d.mod0_elg 
ggcoxzph(d.mod0_elg,font.main = 12, ggtheme = theme_classic2())
```
```{r mod5_elg}
# Example with distance to forest roads and houses
mod5_elg<-coxph(Surv(t.diff, event, type="right") ~ flashed *
              forestroad_d2_ln+ house_d2_ln, data=obs_sp)
summary(mod5_elg)
ggforest(mod5_elg, data = obs_sp)

# Test the proportional hazards assumption
d.mod5_elg <- cox.zph(mod5_elg)  
d.mod5_elg 
ggcoxzph(d.mod5_elg,font.main = 12, ggtheme = theme_classic2())
```



### Red deer
```{r mod0-hjort}
# sp = c("elg","hjort","grevling","gaupe")
sp = "hjort"
# Fitting model with spatial covariates
obs_sp <- obs %>%  # remaking obs_sp, to include the new covariates
  filter(species %in% sp & !period == "Control")

# Example with distance to forest roads and houses
mod0_hjort<-coxph(Surv(t.diff, event, type="right") ~ flashed , data=obs_sp)
summary(mod0_hjort)
ggforest(mod0_hjort, data = obs_sp)

# Test the proportional hazards assumption
d.mod0_hjort <- cox.zph(mod0_hjort)  
d.mod0_hjort 
ggcoxzph(d.mod0_hjort,font.main = 12, ggtheme = theme_classic2())
```

```{r mod5_hjort}
# Example with distance to forest roads and houses
mod5_hjort<-coxph(Surv(t.diff, event, type="right") ~ flashed *
              forestroad_d2_ln+ house_d2_ln, data=obs_sp)
summary(mod5_hjort)
ggforest(mod5_hjort, data = obs_sp)

# Test the proportional hazards assumption
d.mod5_hjort <- cox.zph(mod5_hjort)  
d.mod5_hjort 
ggcoxzph(d.mod5_hjort,font.main = 12, ggtheme = theme_classic2())
```


### Lynx
```{r mod-gaupe}
# sp = c("elg","hjort","grevling","gaupe")
sp = "gaupe"
# Fitting model with spatial covariates
obs_sp <- obs %>%  # remaking obs_sp, to include the new covariates
  filter(species %in% sp & !period == "Control")

# Example with distance to forest roads and houses
mod0_gaupe<-coxph(Surv(t.diff, event, type="right") ~ flashed , data=obs_sp)
summary(mod0_gaupe)
ggforest(mod0_gaupe, data = obs_sp)

# Test the proportional hazards assumption
d.mod0_gaupe <- cox.zph(mod0_gaupe)  
d.mod0_gaupe 
ggcoxzph(d.mod0_gaupe,font.main = 12, ggtheme = theme_classic2())
```
```{r mod5_gaupe}
# Example with distance to forest roads and houses
mod5_gaupe<-coxph(Surv(t.diff, event, type="right") ~ flashed *
              forestroad_d2_ln+ house_d2_ln, data=obs_sp)
summary(mod5_gaupe)
ggforest(mod5_gaupe, data = obs_sp)

# Test the proportional hazards assumption
d.mod5_gaupe <- cox.zph(mod5_gaupe)  
d.mod5_gaupe 
ggcoxzph(d.mod5_gaupe,font.main = 12, ggtheme = theme_classic2())
```






-------------------------------------------------------------
# Session Info



Another solution making use of devtools::session_info() which can be copied straight into an R markdown file (Rmd):
R environment


```{r Reproducibility-SessionInfo-R-packages}
#writeLines(capture.output(sessionInfo()), "sessionInfo.txt")
library(magrittr)
library(devtools)
library(kableExtra)

# kable(session_info(), "latex", booktabs = T) %>%
#   kable_styling(latex_options = c("striped", "scale_down")) %>%
#   row_spec(1, color = "red") %>%
#  as_image(width = 8, file = "Thesis/img/sessinfo.png")
# write_lines("Thesis/tex/sessinfo.tex")
# 
# SI <- sessionInfo() %>% as.list() 
# #SI[[]]
#   as_tibble()
# toLatex() %>% 
# write_lines("Thesis/tex/sessinfo.tex")


df_session_packages <- devtools::session_info()$packages %>% 
  as.data.frame(.) %>% 
  filter(attached == TRUE) %>% 
  dplyr::select(loadedversion, date) %>% 
  rownames_to_column

colnames(df_session_packages) <- c("Package", "Loaded version", "Date")

kable(
  df_session_packages, 
  booktabs = T, 
  align = "l",
  caption = "(ref:Reproducibility-SessionInfo-R-packages-title)", # complete caption for main document
  caption.short = " ", # "(ref:Reproducibility-SessionInfo-R-packages-caption)" # short caption for LoT
  "latex") %>% 
write_lines("../Thesis/tex/sessinfo.tex")

# fileConn<-file("sessinfo.tex")
# output <- capture.output(sessionInfo())
# cat(output, file=fileConn)
# close(fileConn)
```


```{r sessionInfo}
sessionInfo()
# packrat
# checkpoint
```

If you want your code to be reproducible in the long-run (i.e. so you can come back to run it next month or next year), you’ll need to track the versions of the packages that your code uses.
A rigorous approach is to use _packrat_, [link](http://rstudio.github.io/packrat/), which stores packages in your project directory,
or _checkpoint_, [link](https://github.com/RevolutionAnalytics/checkpoint), which will reinstall packages available on a specified date. A quick and dirty hack is to include a chunk that runs sessionInfo() — that won’t let you easily recreate your packages as they are today, but at least you’ll know what they were.