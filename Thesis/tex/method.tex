\chapter{Method and materials}


\section{Study area} % flyttet først etter AMkomm


%https://klimaservicesenter.no/faces/desktop/article.xhtml?uri=klimaservicesenteret/klimaprofiler/klimaprofil-oslo-og-akershus
%https://klimaservicesenter.no/faces/desktop/article.xhtml?uri=klimaservicesenteret%2Fklimaprofiler%2Fklimaprofil-buskerud  
The study area (59.36-60.45° N, 9.31-11.13° E) extends over much of the southeastern parts of Norway in municipalities Flå, Krødsherad, Sigdal, Ringerike, Modum, Hole, Lier, Øvre Eiker, Asker, Oslo, Enebakk, Indre Østfold, Våler, Råde, Moss, Frogn and Vestby in Oslo and Viken counties. 
The climate has a continental character due to rain shadows of the mountain ridges from the west. 


\begin{figure}
\centering
%\includegraphics[scale=•]{•} %TODO
	\label{fig:map}
	\caption[Map of study area]
	{Map of study area %\par \small
	60 sites in Southeastern Norway were included in the survey. Point colouration represents camera model, and white dots represent sites that had periods with an additional white LED camera trap (CT).}
\end{figure}

The mean annual temperatures ranges from 2-6 \celsius , precipitation lies between 700-1500mm and growing season length lies between 170 - 190 days (\cite{Moen1999}).
Topography is predominantly flat towards the south, and more rugged and elevated towards the north. The landscape is a mosaic of forest and agricultural areas, divided with a wide network of gravel roads.
The area is situated in the southern boreal and the boreonemoral zones. %Må finne oppdaterte data (frå Norges vassdrags- og energidirektorat, 2019?)
Norway spruce (\textit{Picea abies}) and Scots pine (\textit{Pinus sylvestris}) make up the dominating boreal coniferous forests, with frequent presence of silver birch (\textit{Betula pendula}) and downy birch (\textit{Betula pubescens}), then aspen (\textit{Populous tremula}), alder (\textit{Alnus incana}) and black alder (\textit{Alnus glutinosa}).



\section{Study design} 

I was given access to CTs used in the Scandlynx project, and chose 60 sites to get a substantial amount of data.
For logistical reasons, I chose the sites closest to Oslo which weren't already equipped with white LED flashes. 
Instead, these CTs were equipped with infra-red flashes, and I will refer to them as the \emph{IR CTs}.


The IR CTs had been installed on trees 1-3 m from wildlife, human or tractor paths, 30-160 cm above ground level, and their distance from houses or roads varied to a large extent.
They were set up and handled by people from NINA and, at the sites further from Oslo, by local volunteers. %members of the Norwegian Hunters and Fishers Society (NJFF). 
The installation of the cameras did not follow a strict protocol, nor were their locations chosen randomly. The overall placement was systematic as decided by NINA, then there was a deliberately-biased placement of the CTs put up in areas where the individual handler deemed it most likely to photograph lynx, and hence, based on a combination of site accessibility and expectations of animal occurrence. % slik som (\cite{Burton2015} seier skal formidlast). 


\begin{figure}
    \begin{center}
    	\includegraphics[scale=0.4]{./img/experiment_setup.jpg} %insert figure of groups     
    \end{center}
\caption[The Experimental setup]
    	{Experiment setup %\par \small
    	 60 sites with preinstalled Infrared Camera Traps (IR CTs) that was divided into three groups, where the first group remained unchanged (control group), and the two other alternated on having additional white LED CTs present or not (treatment groups).}
    \label{fig:exp_set}
\end{figure} 


I divided the sites randomly into three groups of 20 sites.
The first group remained unchanged as a control, and the remaining two groups (hereby referred to as the \emph{treatment groups}) were equipped with an additional white LED camera (hereby referred to as the \emph{white LED CTs}) in alternating 3 month-periods, as illustrated in figure\vref{fig:exp_set}.
Periods when an additional white LED CT was present, I will refer to as \emph{white LED periods}.
Periods when the white LED was absent, I will refer to as \emph{IR periods}.
All periods from the control group, I will refer to as \emph{control periods}.
Note that control periods also are periods with only IR CTs present, but they differ from the IR periods in that there never was a white LED present at these sites.


%After approximately three months, I moved the LED CTs to the other treatment group. The periods were marked as LED\_1, LED\_2 for first and second LED period, and IR\_1, IR\_2 for first and second IR period as seen in figure \vref{fig:timeseries}.
I set up all white LED CTs above the IR CTs already in place (installation examples in figure \ref{fig:cam_ex_main}), using an electric drill. 
I used short logs to adjust the angle of the white LED CTs, aligning it to the IR CTs field of view.
Vegetation obstructing the view of any camera was removed at setup, or when noticed during a later visitation (e.g. tall grass during summer).

 
At one site the IR camera had been installed so far above ground level that I chose to position the white LED CT below the IR CT. %Atle fjerna kryssref til bildet

The camera boxes containing the white LED CTs remained at each site untill the end of the survey. Note that the second treatment group had no extra boxes  before the start of their first white LED period in May 2019.   


\input{tex/fig/met1.tex}


I visited sites of the treatment groups at least once every three months in order to move the white LED cameras.
For logistical reasons I visited sites of the control group less often.
However, as the cameras were part of other, ongoing projects, they were occasionally visited by workers from NINA to retreive the Secure Digital memory cards (hereby SD Cards) for data. %write in full on first mention (-Atle)
This was mostly the case for sites close to, and south of, Oslo, or rather, the cameras not normally operated by local volunteers.




%We quantified the degree of consistency in implementing and reporting features of CT protocols and study design that might affect detectability and sampling error (e.g. camera type and settings, spatial and temporal sampling effort, use of attractants; Table S1). These details are fundamental to interpreting results of CT studies and assessing their reliability, repeatability and suitability for broader comparison or synthesis (Meek et al. 2014a)




\section{Data Collection} 


Five different models of RECONYX™ (address: 3828 Creekside Ln, Ste 2, Holmen, WI 54636, USA, www.reconyx.com) cameras were used, 
and one model of BROWNING™ (address: One Browning Place, Morgan, UT 84050, USA, www.browningtrailcameras.com), details in table \ref{tab:cam_mod} and \ref{tab:cam_set}.



\input{tex/tab/cam_mod.tex}


Cameras were operating 24 hours per day. The RECONYX™ cameras were set to take one time lapse photo per day in order to verify that the cameras had been operational.
They were set to take 3 pictures per series, as fast as possible using \emph{rapidfire}, and retrigger immediately using \emph{no delay}.
The BROWNING™ cameras were also set to rapidfire, but to 8 photos per trigger, which made the memory cards more vulnerable to filling up before being collected. This happened in some areas with sheep and/or cattle, and sometimes due to triggering by vegetation.
Therefore, the BROWNING™ cameras tended to have more gaps of inoperable days.
Lacking time lapse photos, the number of active camera days were confounded.
To approach the true number of active days, I assumed all BROWNING™ cameras to be functional every day, unless the camera was inactive when I visited it. In that case, I considered the camera inactive since the day of its last photo.



As seen in figure \ref{fig:map}, %TODO insert map with loc, white point inside flash-cameras.
there was a correlation between latitude and camera type.

% difference between the two camera types*** 
% Assumptions: chance of detection & sp validation BROWNING > RECONYX, operational days BROWNING < RECONYX



%* Number and spacing of CTs |Hofmeester 2017 
%Mention in map figure text


%* Temperature and weather during the survey 
%Don't have that data as far as I know





\section{Data processing} %TODO
All SD cards were delivered to NINA for data processing.
Firstly, a facial recognition algorithm (FRA) was used to sort all the pictures. %artificial intelligence software (AI)
Afterwards, a human sorter checks the softwares' output, confirming all the correct decisions (i.e. species detections) and correcting all the wrong ones. 
Consequently, the rate of correctly identified species has gone up as the FRA sometimes detect animals that aren't easily noticed by human sorters (John Odden pers. comm.). 
NINA's goal is to fully automate this identification process, which is a request from The Norwegian Data Protection Authority in relation to usage of cameras in densely crowded areas (e.g. parks) (John Odden pers. comm.).

%Nei, vi har ikke publisert artikkel på gjenkjenningsalgoritmen. Du har jo vært med på prosessen sjøl, så jeg veit ikke om du egentlig trenger referanse her, men du kan sette inn John O som pers med og merke det, så kan han eller jeg endre det slik vi mener det bør være når vi leser gjennom oppgava di..
The white LED CTs were considered as external flashes, and so, only the pictures from the preinstalled IR CTs were sorted for species identification.
NINA provided me with a data frame containing time stamps for every triggering of each IR CT, including all meta data from the CTs, coupled with predicted species (FRA output, with a confidence number), verified species (by human sorters), number of animals and distance from camera.

Thus, if a moose ruminated in front of a camera for 30 minutes, the data frame would include several detections in sequence.
In order to remove autocorrelation in the observations, I defined an event to be any sighting of a species that occured more than 20 minutes after the previous sighting of the same species.
Number of individuals was not taken into account.
My predictor variable of interest was the three different types of periods, namely IR, white LED and Control periods.

I extracted metadata from all pictures taken by the white LED CTs and used that to define the duration of each white LED period.
If a white LED CT stopped working (eg. due to full SD card or empty batteries) before the day I came to move it, the site would have already entered its next IR period.
This happened a few times, which can be seen as the times a light blue period starts outside of the shaded areas in figure \ref{fig:timeseries}.
If an IR CT stopped working during a white LED period, that period represented a GAP even though the white LED CT still functioned. Thus, the site, and it's inhabitant animals, would still experience the effect of a white flash up until the start of the IR period.
I never experienced that both the IR and the white LED CTs of a site had stopped working at the same time.

When modelling the detection rates I needed periods of similar lengths to each other. Therefore, I divided the control group-cameras into four periods of similar lengths to that of the IR- and white LED-periods (see figure \ref{fig:timeseries}). 
%Describing in brief how coding is undertaken is useful for readers to understand the methods used in relation to the results.(Meek etal 2014)


In total, 4 sites were removed before the analysis due to technical faults, or alike.
1 CT was removed from the control group, as it turned out to be a white LED camera.
3 CTs were removed from the treatment groups, because of large or frequent gaps due to technical errors, and at one site, ineffective placement of the additional white LED camera. 



\begin{figure}
		\centering
		\includegraphics[scale=.8]{../R/FLM_notebook_files/figure-gfm/effort-facet-1.png}	
\caption[An overview of active camera days]
{An overview of active camera days for each camera %\par \small 
Colours indicate the different periods for each site. White spaces indicate gaps where the IR CTs were inactive. Control camera periods were defined in similar lengths to that of the treatment group during analysis. As a result, the first day of control periods are often set at dates far from when I actually visited the site. Shaded areas represent my field work periods. \label{fig:timeseries}}
\end{figure}


%*************************************************************
%Hypothesis 1: Usage of white LED flash will stress one or more species in general, and therefore lower the detection rate of the stressed species. The effect will likely vary in extent between species.


\section{Statistical analysis} %This is a reference to the session info appendix \ref{app:sessinfo}

To test for effects of the white LED flash I used the R programming language (\cite{RCoreTeam2020}), in the RStudio IDE (\cite{RStudioTeam2020a}), adopting large parts of the tidyverse (\cite{tidyverse}) and the easystats (\cite{easystats}) frameworks along the way. Complete citation of R packages used are presented in appendix \ref{app:sessinfo}. 
%TODO easystats referanse


	\subsection*{GLMM}
To test H1 I looked for differences in detection rate per day, using Generalised Linear Mixed Models (GLMM) with the glmer function from the R package lme4 (\cite{lme4}).
I fitted separate models for each species to avoid overly complicated models. 
Locations that had 0 observations of the modelled species were filtered out before the modelling, but for all locations that had observed the species, all periods were included.
The dependent variable was count data (number of observations), and I therefore assumed the error term followed a Poisson distribution ($ X \sim Pois(\lambda) $).

I included location ID and week of the year as random effects to account for consistent differences between camera sites and seasonal changes during the year of study.
95\% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.
I used standardized parameters (mean = 0, SD = 1) to enable comparison of effect sizes.

The main term of interest was time since deployment interacting with type of flash period (formula: n.obs $\sim$ time.deploy $\ast$ flash).
For the sites that were equipped with an additional white LED camera, time since deployment starts from the day I visited the camera, and set up/ took down the white LED.
The control group’s “day 0” of time since deployment were set at points reflecting the onset of field work each time, in order to obtain periods of similar lengths to that of the white LED-locations.

I trimmed the period lengths down to a reduced maximum length, based on the median length of the IR and white LED periods, to enhance meaningful comparison.
Thus, any period exceeding the shortest median length, was trimmed down, as visualized in figure \ref{fig:median_period}.
Finally, due to large eigenvalues in the fixed effects, the model failed to converge, and an error message prompted me to rescale variables.
Therefore I divided the time since deployment-variable by ten, which solved the convergence issue.
Consequently, the time axis is shown in days/10, which means that 8 corresponds to 80 days.


\begin{figure}
	\centering
	\includegraphics[scale=.8]{../R/glmm_sp_files/figure-html/period-length-wControl-1.png}
	\caption[Period lengths]
	{Period lengths %\par \small 
	Vertical line represents the median IR period length, which was shorter than the median of the other groups. Data superceding the median were trimmed away for the GLMM. \label{fig:median_period}}
\end{figure}

%AMkomm: til analyse
If there were any effect of the white LED, the IR period should show a regression to the norm, ie. counteracting the trend during the white LED periods.
Thus, if the white LED had a negative slope along the time axis, the IR should have a positive slope.
Further, the detection rate at the start of each period, should correspond somewhat to the detection rate at the end of the previous period. Still, that pattern could be skewed to some extent due to my visitation of each location at the start of all IR and white LED periods.






\subsection*{Equivalence test}
% Multiple testing i arkiv/method-ark
I used the standard significance level of $\alpha = .05$, and performed an equivalence test on my model outputs, using the function equivalence\_test from the R package parameters ().%\cite{package-parameters}). %TODO
In an equivalence test, model parameters are tested against a Region of Practical Equivalence (ROPE) as opposed to merely one single mean value, thus accounting for the \emph{effect size} of each parameter.
If the parameters estimate and CI falls outside the ROPE, their null hypothesis is rejected. However, if the CI is inside the ROPE, H0 is accepted, no matter if a standard Null Hypothesis Significance Test (NHST) would have deemed it significant.

Inside the function equivalence\_test I used the Two One-Sided Tests (TOST) rule, where the confidence interval (CI) is set to $1 - 2\times \alpha$. In my case that gave a narrow CI of 0.90.
For models from count data, the residual variance is often used to define the ROPE range. However, the description of the rope\_range function from the package bayestestR () states this threshold as "rather experimental" and that the range is probably often similar to the default [-0.1, 0.1] of a standardized parameter (www.easystats.github.io/bayestestR/reference/rope\_range.html, accessed 11.3.2021). %TODO betre ref-metode for nettsider
Hence, I used the default ROPE range which corresponds to a negligible effect size according to Cohen, 1988.

%In the TOST procedure, the null hypothesis is the presence of a true effect of DL or DU, and the alternative hypothesis is an effect that falls within the equivalence bounds or the absence of an effect that is worthwhile to examine. \cite{Lakens2017}










